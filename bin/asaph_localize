#!/usr/bin/env python3
"""
Copyright 2018 Ronald J. Nowling

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

"""
Command-line tool for localizing chromosomal inversions and genetic variants using statistical association tests.
This tool creates Manhattan plots and window plots to visualize genetic associations, detects inversion boundaries
using statistical significance testing, evaluates predicted boundaries against known regions, and performs
association tests between principal components and genetic variants. It provides comprehensive functionality for
identifying and characterizing structural genetic variations in population genomic datasets.
"""

import argparse
from collections import defaultdict
import os
import sys

import matplotlib
matplotlib.use("PDF")
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy.stats as stats
from sklearn.metrics import jaccard_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

from asaph.feature_extraction import FeatureStringsExtractor
from asaph.newioutils import *
from asaph.vcf import filter_invariants
from asaph.vcf import VCFStreamer

plt.rcParams["savefig.dpi"] = 200

ALPHA = 0.01

def read_snp_table(flname, component, chromosome=None):
    with open(flname) as fl:
        df = pd.read_csv(fl, delim_whitespace=True)
        df["chrom"] = df["chrom"].astype(str)

        if chromosome is None:
            chromosomes = set(df["chrom"])
            if len(chromosomes) > 1:
                print("SNPs for more than one chromosome are present in the association file.  Use the --chromosome flag to indicate which chromosome should be plotted.")
                sys.exit(1)

            chromosome = next(iter(chromosomes))

        mask = (df["chrom"] == chromosome) & (df["component"] == component)
        df = df[mask]

        if len(df) == 0:
            print("No association tests for the given chromosome or component.")
            sys.exit(1)

        df = df.sort_values(by="pos")

    return df

def mark_significant_snps(df, n_samples, threshold=None):
    if threshold is None:
        threshold = ALPHA / n_samples

    df["is_significant"] = 0.0
    mask = df["pvalue"] < threshold
    df.loc[mask, "is_significant"] = 1.0

    return df

def find_inversion_boundaries(df, n_windows, threshold=None):
    min_pos = min(df["pos"])
    max_pos = max(df["pos"])
    windows = np.linspace(min_pos, max_pos, num=n_windows)
    left_boundary = None
    right_boundary = None
    if threshold is None:
        threshold = 0.0001 / len(windows)

    # expected probability of a SNP being
    # significant assuming uniform distribution
    n_sig_snps = len(df[df["is_significant"] == 1])
    exp_prob = n_sig_snps / len(df)

    n_sig_wins = 0
    for i in range(n_windows - 1):
        mask = (df["pos"] >= windows[i]) & (df["pos"] < windows[i+1])
        df_window = df[mask]

        # number of trials (SNPs per window)
        win_snps = len(df_window)

        # number of successes (sig SNPs per window)
        win_sig_snps = len(df_window[df_window["is_significant"] == 1])

        if win_snps > 0:
            win_result = stats.binomtest(win_sig_snps,
                                         win_snps,
                                         exp_prob,
                                         alternative="greater")

            if win_result.pvalue < threshold:
                n_sig_wins += 1
                right_boundary = max(df_window["pos"])
                if left_boundary is None:
                    left_boundary = min(df_window["pos"])

    print(n_sig_wins, "of", n_windows, "were significant")

    return left_boundary, right_boundary

def manhattan_plot(plot_fl, snp_pvalues, boundaries=None, y_limit=None,
				   insig_color=None, sig_color=None):
    log10pvalues = -np.log10(df["pvalue"])
    max_value = max(log10pvalues)

    if boundaries != None:
        left_boundary, right_boundary = boundaries

        plt.plot([left_boundary, left_boundary],
                 [0, max_value],
                 "k-",
                 label="Boundary")

        plt.plot([right_boundary, right_boundary],
                 [0, max_value],
                 "k-")

        plt.legend()

    df_insign = df[df["is_significant"] == 0]
    if len(df_insign) != 0:
        log10pvalues = -np.log10(df_insign["pvalue"])
        plt.scatter(df_insign["pos"],
                    log10pvalues,
                    marker=".",
                    color=insig_color)

    df_sig = df[df["is_significant"] == 1]
    if len(df_sig) != 0:
        log10pvalues = -np.log10(df_sig["pvalue"])
        plt.scatter(df_sig["pos"],
                    log10pvalues,
                    marker=".",
                    color=sig_color,
                    label="Significant")

    plt.xlabel("Position (bp)", fontsize=16)
    plt.ylabel("SNP p-value (-log10)", fontsize=16)

    if y_limit:
        plt.ylim([0, y_limit])
    else:
        plt.ylim([0.0, max_value])

    plt.savefig(plot_fl)

def overlaps(range1, range2):
    if range2[0] <= range1[0] <= range2[1] or range2[0] <= range1[1] <= range2[1]:
        return True
    if range1[0] <= range2[0] <= range1[1] or range1[0] <= range2[1] <= range1[1]:
        return True

    return False

def window_plot(plot_fl, snp_pvalues, window_size, boundaries=None, highlights=None):
    sig_counts = defaultdict(int)
    total_counts = defaultdict(int)
    for _, row in snp_pvalues.iterrows():
        win_idx = row.pos // window_size
        total_counts[win_idx] += 1
        if row.is_significant:
            sig_counts[win_idx] += 1

    xs = []
    ys = []
    for win_idx, win_total in sorted(total_counts.items()):
        xs.append(win_idx * window_size)
        xs.append((win_idx + 1) * window_size)
        ys.append(sig_counts[win_idx] / win_total)
        ys.append(sig_counts[win_idx] / win_total)

    plt.plot(xs, ys, color="tab:purple")

    if highlights is not None:
        xs = []
        ys = []
        for win_idx, win_total in sorted(total_counts.items()):
            left = win_idx * window_size
            right = (win_idx + 1) * window_size

            for i in range(0, len(highlights), 2):
                highlight_range = (highlights[i], highlights[i+1])
                if overlaps((left, right), highlight_range):
                    xs.append(left)
                    xs.append(right)
                    ys.append(sig_counts[win_idx] / win_total)
                    ys.append(sig_counts[win_idx] / win_total)
                    break

        plt.plot(xs, ys, color="tab:orange")


    plt.xlabel("Position (bp)", fontsize=16)
    plt.ylabel("Significant SNPs (%)", fontsize=16)

    if boundaries is not None:
        left_boundary, right_boundary = boundaries

        plt.plot([left_boundary, left_boundary],
                 [0, 0.5],
                 "k-")

        plt.plot([right_boundary, right_boundary],
                 [0, 0.5],
                 "k-")


    plt.ylim([0, 0.5])
    plt.savefig(plot_fl)

def read_pca_coordinates(flname):
    sample_coordinates = []
    sample_names = []
    with open(flname) as fl:
        # skip header
        next(fl)
        for ln in fl:
            cols = ln.split("\t")

            sample_name = cols[0]
            coordinates = list(map(float, cols[1:]))

            sample_names.append(sample_name)
            sample_coordinates.append(coordinates)

    coordinates = np.array(sample_coordinates)

    return sample_names, coordinates

def run_association_tests(variants, pc_coordinates, components):
    for variant_label, string_features in variants:
        for component in components:
            coords = pc_coordinates[:, component - 1]
            feature_to_coords = defaultdict(list)
            for i, (_, feature) in enumerate(string_features):
                if feature is not None:
                    feature_to_coords[feature].append(coords[i])

            if len(feature_to_coords) < 2:
                pvalue = 1.0
            else:
                _, pvalue = stats.f_oneway(*feature_to_coords.values())

                if np.isnan(pvalue) or np.isinf(pvalue):
                    pvalue = 1.0

            yield component, variant_label, pvalue

def write_test_results(flname, test_stream):
    with open(flname, "w") as fl:
        next_output = 1

        headers = ["component", "chrom", "pos", "pvalue"]
        fl.write("\t".join(headers))
        fl.write("\n")

        for i, (compon, (pos_label), pvalue) in enumerate(test_stream):
            chrom, pos = pos_label
            if i == next_output:
                print(i, "Component", compon, "Position", pos_label, "has p-value", pvalue)
                next_output *= 2

            fl.write("\t".join([str(compon), chrom, str(pos), "%.2E" % pvalue]))
            fl.write("\n")

def evaluate_predicted_boundaries(expected, predicted):
    if predicted[0] is not None:
        min_left = min(expected[0], predicted[0])
    else:
        min_left = 1

    if predicted[1] is not None:
        min_right = max(expected[1], predicted[1])
    else:
        min_right = 1_000_000_000

    size = min_right - min_left + 1

    expected_array = np.zeros(size)
    expected_size = expected[1] - expected[0] + 1
    expected_offset = expected[0] - min_left
    for i in range(expected_size):
        expected_array[i + expected_offset] = 1.0

    predicted_array = np.zeros(size)
    predicted_size = predicted[1] - predicted[0] + 1
    predicted_offset = predicted[0] - min_left
    for i in range(predicted_size):
        predicted_array[i + predicted_offset] = 1.0

    precision = precision_score(expected_array, predicted_array)
    recall = recall_score(expected_array, predicted_array)
    jaccard = jaccard_score(expected_array, predicted_array)

    print("Left expected boundary: {}".format(expected[0]))
    print("Right expected boundary: {}".format(expected[1]))
    print()
    print("Left predicted boundary: {}".format(predicted[0]))
    print("Right predicted boundary: {}".format(predicted[1]))
    print()
    print("Recall: {:.1%}".format(recall))
    print("Precision: {:.1%}".format(precision))
    print("Jaccard: {:.1%}".format(jaccard))

def parseargs():
    parser = argparse.ArgumentParser()

    parser.add_argument("--workdir",
                        type=str,
                        required=True)

    subparsers = parser.add_subparsers(dest="mode")

    plot_parser = subparsers.add_parser("manhattan-plot",
                                        help="Create Manhattan plot")

    plot_parser.add_argument("--component",
                             required=True,
                             type=int)

    plot_parser.add_argument("--chromosome",
                             type=str)

    plot_parser.add_argument("--y-limit",
                             type=float)

    plot_parser.add_argument("--boundaries",
                             type=int,
                             nargs=2)

    plot_parser.add_argument("--insig-color",
                            type=str,
                            help="Color for insignificant SNPs (default: matplotlib default)")

    plot_parser.add_argument("--sig-color",
                            type=str,
                            help="Color for significant SNPs (default: matplotlib default)")

    window_parser = subparsers.add_parser("window-plot",
                                          help="Create plot of percentage of significant SNPs per window")

    window_parser.add_argument("--component",
                               required=True,
                               type=int)

    window_parser.add_argument("--chromosome",
                               type=str)

    window_parser.add_argument("--window-size",
                               type=int,
                               required=True)

    window_parser.add_argument("--boundaries",
                               type=int,
                               nargs=2)

    window_parser.add_argument("--highlights",
                               type=int,
                               nargs="*")

    boundary_parser = subparsers.add_parser("detect-boundaries",
                                            help="Detect inversion boundaries")

    boundary_parser.add_argument("--component",
                                 required=True,
                                 type=int)

    boundary_parser.add_argument("--chromosome",
                                 type=str)

    boundary_parser.add_argument("--n-windows",
                                 type=int,
                                 default=10000)

    eval_parser = subparsers.add_parser("evaluate-boundaries",
                                            help="Evaluate boundary predictions")

    eval_parser.add_argument("--component",
                             required=True,
                             type=int)

    eval_parser.add_argument("--n-windows",
                             type=int,
                             default=10000)

    eval_parser.add_argument("--boundaries",
                             type=int,
                             nargs=2,
                             required=True)

    eval_parser.add_argument("--chromosome",
                             type=str)

    association_parser = subparsers.add_parser("association-tests",
                                               help="Run PCA association tests for plotting and boundary detection")

    format_group = association_parser.add_mutually_exclusive_group(required=True)
    format_group.add_argument("--vcf", type=str, help="VCF file to import")
    format_group.add_argument("--vcf-gz", type=str, help="Gzipped VCF file to import")

    association_parser.add_argument("--allele-min-freq-threshold",
                                    type=float,
                                    help="Minimum allele frequency allowed",
                                    default=0.000001)

    association_parser.add_argument("--components",
                                    type=int,
                                    nargs="+")

    return parser.parse_args()

if __name__ == "__main__":
    args = parseargs()

    pca_assoc_tsv = os.path.join(args.workdir, "pca_associations.tsv")

    if args.mode == "manhattan-plot":
        proj_path = os.path.join(args.workdir, PROJECT_SUMMARY_FLNAME)
        proj_summary = deserialize(proj_path)

        n_samples = proj_summary.n_samples

        df = read_snp_table(pca_assoc_tsv,
                            args.component,
                            chromosome=args.chromosome)

        # avoid domain errors from trying to take the log of 0
        df["pvalue"] = np.maximum(df["pvalue"], np.power(10., -300.))

        df = mark_significant_snps(df, n_samples)

        plot_dir = os.path.join(args.workdir, "plots")
        if not os.path.exists(plot_dir):
            os.makedirs(plot_dir)

        chrom = ""
        if args.chromosome:
            chrom = "_chrom{}".format(args.chromosome)

        plot_fl = os.path.join(plot_dir,
                               "manhattan_pc{}{}.png".format(args.component,
                                                             chrom))
        manhattan_plot(plot_fl,
                       df,
                       boundaries = args.boundaries,
                       y_limit = args.y_limit,
                       insig_color=args.insig_color,
                       sig_color=args.sig_color)

    elif args.mode == "window-plot":
        if args.highlights is not None:
            if len(args.highlights) % 2 != 0:
                print("The number of highlight coordinates must be even.")
                sys.exit(1)

        proj_path = os.path.join(args.workdir, PROJECT_SUMMARY_FLNAME)
        proj_summary = deserialize(proj_path)

        n_samples = proj_summary.n_samples

        df = read_snp_table(pca_assoc_tsv,
                            args.component,
                            chromosome=args.chromosome)

        # avoid domain errors from trying to take the log of 0
        df["pvalue"] = np.maximum(df["pvalue"], np.power(10., -300.))

        df = mark_significant_snps(df, n_samples)

        plot_dir = os.path.join(args.workdir, "plots")
        if not os.path.exists(plot_dir):
            os.makedirs(plot_dir)

        chrom = ""
        if args.chromosome:
            chrom = "_chrom{}".format(args.chromosome)

        plot_fl = os.path.join(plot_dir,
                               "window_pc{}{}.png".format(args.component,
                                                          chrom))
        window_plot(plot_fl,
                    df,
                    args.window_size,
                    boundaries = args.boundaries,
                    highlights = args.highlights)

    elif args.mode == "detect-boundaries":
        proj_path = os.path.join(args.workdir, PROJECT_SUMMARY_FLNAME)
        proj_summary = deserialize(proj_path)

        n_samples = proj_summary.n_samples

        df = read_snp_table(pca_assoc_tsv,
                            args.component,
                            chromosome=args.chromosome)

        df = mark_significant_snps(df, n_samples)

        left_boundary, right_boundary = find_inversion_boundaries(df,
                                                                  args.n_windows)

        print("Left boundary: {}".format(left_boundary))
        print("Right boundary: {}".format(right_boundary))

    elif args.mode == "evaluate-boundaries":
        proj_path = os.path.join(args.workdir, PROJECT_SUMMARY_FLNAME)
        proj_summary = deserialize(proj_path)

        n_samples = proj_summary.n_samples

        df = read_snp_table(pca_assoc_tsv,
                            args.component,
                            chromosome=args.chromosome)

        df = mark_significant_snps(df, n_samples)

        left_boundary, right_boundary = find_inversion_boundaries(df,
                                                                  args.n_windows)

        evaluate_predicted_boundaries(args.boundaries,
                                      [left_boundary, right_boundary])

    elif args.mode == "association-tests":
        coordinates_fl = os.path.join(args.workdir, "pca_coordinates.tsv")
        sample_names, coordinates = read_pca_coordinates(coordinates_fl)

        if args.vcf is not None:
            flname = args.vcf
            gzipped = False
        else:
            flname = args.vcf_gz
            gzipped = True

        # the VCF streamer should return the
        # variants in the order of the given
        # kept_individuals parameter
        stream = VCFStreamer(flname,
                             gzipped,
                             kept_individuals = sample_names)

        filtered_variants = filter_invariants(args.allele_min_freq_threshold,
                                              stream)

        string_features = FeatureStringsExtractor(filtered_variants)

        test_stream = run_association_tests(string_features,
                                            coordinates,
                                            args.components)

        write_test_results(pca_assoc_tsv,
                           test_stream)

    else:
        print("Unknown mode '{}'".format(args.mode))
        sys.exit(1)
