#!/usr/bin/env python3

"""
Command-line tool for performing Principal Component Analysis (PCA) on genetic variation data.
This tool constructs feature matrices from VCF files using various feature types and sampling methods,
trains PCA models to reduce dimensionality while preserving genetic structure, and creates visualization
plots of principal component projections. It supports both allele count and genotype category features,
multiple sampling strategies for large datasets, and customizable dimensionality reduction parameters
for population genetic analysis.

Copyright 2015 Ronald J. Nowling

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

import argparse
from collections import defaultdict
import os
import sys

import joblib
import matplotlib
matplotlib.use("PDF")
import matplotlib.pyplot as plt
import numpy as np
from sklearn.decomposition import PCA
from sklearn.random_projection import johnson_lindenstrauss_min_dim as jl_min_dim

from asaph.feature_matrix_construction import construct_feature_matrix
from asaph.models import ProjectSummary
from asaph.newioutils import COORDINATES_FLNAME
from asaph.newioutils import FEATURES_FLNAME
from asaph.newioutils import MODEL_FLNAME
from asaph.newioutils import MODEL_KEY
from asaph.newioutils import PROJECT_SUMMARY_FLNAME
from asaph.newioutils import PROJECTION_KEY
from asaph.newioutils import SAMPLE_LABELS_FLNAME
from asaph.newioutils import serialize
from asaph.vcf import stream_vcf_variants

plt.rcParams["savefig.dpi"] = 200

def calculate_dimensions(n_samples, args):
    n_dim = -1
    if args.num_dimensions is None and args.min_inversion_fraction is None:
        n_dim = jl_min_dim(n_samples, eps=0.05)
    elif args.min_inversion_fraction is not None:
        if not 0.0 < args.min_inversion_fraction < 1.0:
            raise Exception("Minimum inversion fraction must be a number between 0 and 1 (exclusive).")
        n_dim = jl_min_dim(n_samples, eps=args.min_inversion_fraction)
    elif args.num_dimensions is not None:
        n_dim = args.num_dimensions

    return n_dim

def import_vcf(args):
    if args.vcf is not None:
        flname = args.vcf
        gzipped = False
    else:
        flname = args.vcf_gz
        gzipped = True

    variant_stream, individual_names = stream_vcf_variants(flname,
                                                           gzipped,
                                                           args.allele_min_freq_threshold)

    n_samples = len(individual_names)
    n_dim = calculate_dimensions(n_samples, args)

    sampling_method = args.sampling_method
    if sampling_method == "none":
        sampling_method = None

    feature_matrix = construct_feature_matrix(variant_stream,
                                              n_samples,
                                              args.feature_type,
                                              sampling_method,
                                              n_dim)

    print(feature_matrix.shape[0], "individuals")
    print(feature_matrix.shape[1], "features")

    project_summary = ProjectSummary(n_features = feature_matrix.shape[1],
                                     n_samples = feature_matrix.shape[0],
                                     feature_type = args.feature_type,
                                     sampling_method = sampling_method,
                                     sample_names = individual_names,
                                     explained_variance_ratios = None)

    print("Variants imported")

    return feature_matrix, project_summary

def write_project(workdir, project_summary, pca_model, feature_matrix):
    if not os.path.exists(workdir):
        os.makedirs(workdir)

    serialize(os.path.join(workdir, SAMPLE_LABELS_FLNAME), project_summary.sample_names)
    serialize(os.path.join(workdir, PROJECT_SUMMARY_FLNAME), project_summary)
    serialize(os.path.join(workdir, FEATURES_FLNAME), feature_matrix)

    models_dir = os.path.join(workdir, "models")
    model_fl = os.path.join(models_dir, MODEL_FLNAME)
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)

    joblib.dump(pca_model,
                model_fl)

    output_coordinates(workdir,
                       pca_model[PROJECTION_KEY],
                       project_summary.sample_names)

def train_pca(feature_matrix, project_summary, args):
    print(f"Training PCA model with {args.n_components} components")
    pca = PCA(n_components = args.n_components,
              whiten = True)

    projections = pca.fit_transform(feature_matrix)

    print("Explained variance ratios:", pca.explained_variance_ratio_)
    project_summary = project_summary._replace(explained_variance_ratios =
                                               pca.explained_variance_ratio_)

    model = { MODEL_KEY : pca,
              PROJECTION_KEY : projections}

    return model, project_summary

def output_coordinates(workdir, projections, sample_names):
    fl_path = os.path.join(workdir, COORDINATES_FLNAME)
    n_components = projections.shape[1]
    with open(fl_path, "wt", encoding="utf-8") as fl:
        headers = ["sample"]
        headers.extend(map(str, range(1, n_components + 1)))
        fl.write("\t".join(headers))
        fl.write("\n")

        for i, sample_name in enumerate(sample_names):
            line = [sample_name]
            line.extend(map(str, projections[i, :]))
            fl.write("\t".join(line))
            fl.write("\n")

def read_pca_coordinates(flname):
    if not os.path.exists(flname):
        print("Coordinates file path is invalid")
        sys.exit(1)

    sample_coordinates = []
    sample_names = []
    with open(flname, "rt", encoding="utf-8") as fl:
        # skip header
        next(fl)
        for ln in fl:
            cols = ln.split("\t")

            sample_name = cols[0]
            coordinates = list(map(float, cols[1:]))

            sample_names.append(sample_name)
            sample_coordinates.append(coordinates)

    coordinates = np.array(sample_coordinates)

    return sample_names, coordinates

def read_label_names(flname):
    sample_indices = dict()

    with open(flname, "rt", encoding="utf-8") as fl:
        for label_idx, ln in enumerate(fl):
            cols = ln.strip().split(",")

            label = cols[0]

            for sample_name in cols[1:]:
                sample_indices[sample_name] = label

    return sample_indices

def pairwise(iterable):
    iterable = iter(iterable)
    try:
        while True:
            a = next(iterable)
            b = next(iterable)
            yield a, b
    except StopIteration:
        pass

def plot_projections(workdir, pairs, labels=None):
    coordinates_fl = os.path.join(workdir, "pca_coordinates.tsv")
    sample_names, coordinates = read_pca_coordinates(coordinates_fl)

    if len(pairs) % 2 != 0:
        print("Error: PCs must be provided in pairs of 2")
        sys.exit(1)

    dirname = os.path.join(workdir, "plots")
    if not os.path.exists(dirname):
        os.makedirs(dirname)

    for p1, p2 in pairwise(pairs):
        fig_flname = os.path.join(dirname,
                                  "pca_projection_%s_%s.png" % (str(p1), str(p2)))
        plt.clf()

        if labels is None:
            plt.scatter(coordinates[:, p1 - 1],
                        coordinates[:, p2 - 1])
        else:
            label_samples = defaultdict(list)
            for idx, sample_name in enumerate(sample_names):
                label_name = labels[sample_name]
                label_samples[label_name].append(idx)

            for _, (label, samples) in enumerate(label_samples.items()):
                if label != "-1":
                    plt.scatter(coordinates[samples, p1 - 1],
                                coordinates[samples, p2 - 1],
                                label=label)

            if "-1" in label_samples:
                samples = label_samples["-1"]
                plt.scatter(coordinates[samples, p1 - 1],
                            coordinates[samples, p2 - 1],
                            color="k")

            plt.legend()

        plt.xlabel("Component %s" % p1, fontsize=16)
        plt.ylabel("Component %s" % p2, fontsize=16)
        plt.savefig(fig_flname)

def parseargs():
    parser = argparse.ArgumentParser(description="Asaph")

    parser.add_argument("--workdir",
                        type=str,
                        required=True,
                        help="Work directory")

    subparsers = parser.add_subparsers(dest="mode", required=True)

    pca_parser = subparsers.add_parser("pca",
                                          help="Run PCA")

    pca_parser.add_argument("--n-components",
                            type=int,
                            default=10,
                            help="Number of PCs to compute")

    pca_parser.add_argument("--feature-type",
                            type=str,
                            default="allele-counts",
                            choices=["allele-counts",
                                     "genotype-categories"])

    pca_parser.add_argument("--sampling-method",
                            type=str,
                            default="bottom-k",
                            choices=["feature-hashing",
                                     "reservoir",
                                     "bottom-k",
                                     "none"])

    dimensions_group = pca_parser.add_mutually_exclusive_group()
    dimensions_group.add_argument("--num-dimensions",
                                  type=int,
                                  default=None,
                                  help="Set number of dimensions to use for reduced space." )

    dimensions_group.add_argument("--min-inversion-fraction",
                                  type=float,
                                  help="Use minimum inversion size (in terms of fraction of SNPs) to estimate number of dimensions needed.")

    format_group = pca_parser.add_mutually_exclusive_group(required=True)
    format_group.add_argument("--vcf", type=str, help="VCF file to import")
    format_group.add_argument("--vcf-gz", type=str, help="Gzipped VCF file to import")

    pca_parser.add_argument("--selected-samples",
                               type=str,
                               help="Use only these samples")

    pca_parser.add_argument("--allele-min-freq-threshold",
                               type=float,
                               help="Minimum allele frequency allowed",
                               default=0.000001)

    plot_parser = subparsers.add_parser("plot-projections",
                                        help="Plot PCA projections")

    plot_parser.add_argument("--pairs",
                             nargs="+",
                             type=int,
                             required=True)

    plot_parser.add_argument("--labels-fl",
                             type=str,
                             help="Labels file to use in coloring points")

    return parser.parse_args()

if __name__ == "__main__":
    args = parseargs()

    if args.mode == "pca":
        features, project_summary = import_vcf(args)
        pca_model, project_summary = train_pca(features,
                                               project_summary,
                                               args)
        write_project(args.workdir,
                      project_summary,
                      pca_model,
                      features)
    elif args.mode == "plot-projections":
        labels = None
        if args.labels_fl:
            labels = read_label_names(args.labels_fl)
        plot_projections(args.workdir,
                         args.pairs,
                         labels=labels)
    else:
        print("Unknown mode {}".format(args.mode))
        sys.exit(1)
